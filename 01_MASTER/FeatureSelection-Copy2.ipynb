{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ab9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import confusion_matrix, classification_report, mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_recall_curve\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from xgboost import XGBRegressor, XGBClassifier, plot_importance\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif\n",
    "from sklearn.decomposition import PCA, FactorAnalysis\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras import regularizers\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c8c14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('survey_PE.csv')\n",
    "\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "\n",
    "#-------------------------------------------------------CORRELATION MATRIX------------------------------------------------------\n",
    "\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, \n",
    "            annot=False, \n",
    "            fmt=\".2f\", \n",
    "            cmap='coolwarm', \n",
    "            center=0,\n",
    "            linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix of Features\")\n",
    "plt.show()\n",
    "\n",
    "upper_triangle = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "high_corr_pairs = (corr_matrix.where(~upper_triangle)\n",
    "                  .stack()\n",
    "                  .reset_index()\n",
    "                  .rename(columns={'level_0':'Feature1', 'level_1':'Feature2', 0:'Correlation'}))\n",
    "\n",
    "high_corr_pairs = (high_corr_pairs[abs(high_corr_pairs['Correlation']) < 1]\n",
    "                  .sort_values(by='Correlation', key=abs, ascending=False))\n",
    "\n",
    "top_n = 20\n",
    "print(f\"Top {top_n} correlating feature pairs (|r| < 1):\")\n",
    "print(high_corr_pairs.head(top_n).to_string(index=False))\n",
    "\n",
    "#-------------------------------------------------------MAKE TO CLASSIFICATION PROBLEM----------------------------------------------------\n",
    "\n",
    "threshold = 0.0331\n",
    "treshold2 = 0.0328\n",
    "\n",
    "df['is_price_responsive'] = df['Price_elasticity'].apply(\n",
    "    lambda x: 1 if x < -threshold else (0 if x > treshold2 else None)\n",
    ")\n",
    "\n",
    "df = df.dropna(subset=['is_price_responsive'])\n",
    "\n",
    "counts = df['is_price_responsive'].value_counts()\n",
    "print(\"Counts of each class:\")\n",
    "print(counts)\n",
    "\n",
    "\n",
    "X = df.drop(columns=[\"is_price_responsive\", \"Price_elasticity\", 'ID'])\n",
    "y = df['is_price_responsive']\n",
    "\n",
    "print(\"Features (X):\", list(X.columns)) \n",
    "\n",
    "print(\"Target (y):\", y.name)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0844f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------FEATURE SCALING -----------------------------------------------------\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X_train),\n",
    "    columns=X_train.columns,  \n",
    "    index=X_train.index       \n",
    ")\n",
    "X_test_scaled = pd.DataFrame(\n",
    "    scaler.transform(X_test),\n",
    "    columns=X_test.columns,\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "#----------------------------------------------------------DOMAIN FEATURES-----------------------------------------------------\n",
    "\n",
    "selected_features = ['Q4', 'Q7', 'Q13_5', 'Q16', 'Q17', 'Q20', \n",
    "                    'Q21', 'Q22', 'Q27_5', 'Q29']\n",
    "\n",
    "X_train_domain = X_train_scaled[selected_features]\n",
    "X_test_domain = X_test_scaled[selected_features]\n",
    "\n",
    "\n",
    "#---------------------------------------------------------FORWARD SELECTION-----------------------------------------------------\n",
    "\n",
    "model = LogisticRegression(max_iter=10000, solver='saga', C=0.1,class_weight='balanced')\n",
    "\n",
    "sfs = SFS(model, k_features=8, forward=True, floating=False, scoring=\"accuracy\", cv=5)\n",
    "\n",
    "sfs.fit(X_train_scaled, y_train)\n",
    "\n",
    "accuracy = sfs.k_score_\n",
    "\n",
    "selected_features = list(sfs.k_feature_names_)\n",
    "\n",
    "X_train_FS = X_train_scaled[selected_features]\n",
    "X_test_FS = X_test_scaled[selected_features]\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Selected Features:\", sfs.k_feature_names_)\n",
    "\n",
    "sfs_df = pd.DataFrame.from_dict(sfs.get_metric_dict()).T\n",
    "sfs_df[\"avg_score\"] = sfs_df[\"avg_score\"].astype(float)\n",
    "fig, ax = plt.subplots()\n",
    "sfs_df.plot(kind=\"line\", y=\"avg_score\", ax=ax)\n",
    "ax.set_xlabel(\"Number of Features\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Forward Selection Performance\")\n",
    "plt.show()\n",
    "\n",
    "#-----------------------------------------------------------FISHER SCORE-------------------------------------------------------\n",
    "\n",
    "def manual_fisher_score(X, y):\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    classes = np.unique(y)\n",
    "    scores = []\n",
    "    \n",
    "    for feature in X.T:  # Loop through each feature\n",
    "        overall_mean = np.mean(feature)\n",
    "        \n",
    "        between_var = sum(\n",
    "            [np.sum(y == cls) * (np.mean(feature[y == cls]) - overall_mean)**2 \n",
    "            for cls in classes])\n",
    "        \n",
    "        within_var = sum([np.var(feature[y == cls]) * np.sum(y == cls) for cls in classes])\n",
    "        \n",
    "        fisher_score = between_var / (within_var + 1e-9)\n",
    "        scores.append(fisher_score)\n",
    "    \n",
    "    return np.array(scores)\n",
    "\n",
    "ranks = manual_fisher_score(X_train_scaled, y_train)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train_scaled.columns, \n",
    "    'Fisher_Score': ranks\n",
    "}).sort_values('Fisher_Score', ascending=False)\n",
    "\n",
    "feature_importance['Percentile'] = (\n",
    "    feature_importance['Fisher_Score'].rank(pct=True).round(2) * 100\n",
    ")\n",
    "\n",
    "print(\"Top 10 Features Fisher Scores:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "#-----------------------------------------------------------CHI SQUARED-------------------------------------------------------\n",
    "\n",
    "X_train_chi2 = X_train.copy()\n",
    "\n",
    "discretizer = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')\n",
    "X_train_chi2['Q_Age'] = discretizer.fit_transform(X_train_chi2[['Q_Age']])\n",
    "\n",
    "X_train_chi2 = X_train_chi2.astype(int)\n",
    "chi_scores, p_values = chi2(X_train_chi2, y_train)\n",
    "\n",
    "chi2_results = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Chi2_Score': chi_scores,\n",
    "    'p_value': p_values\n",
    "}).sort_values('Chi2_Score', ascending=False)\n",
    "\n",
    "# Filter features on: p-value < 0.05 \n",
    "significant_features = chi2_results[chi2_results['p_value'] < 0.4]\n",
    "print(\"Significant Features by Chi-Squared Test (p < 0.05):\")\n",
    "print(significant_features)\n",
    "\n",
    "#---------------------------------------------------------INFORMATION GAIN-----------------------------------------------------\n",
    "\n",
    "def compute_stable_mi(X, y, n_runs=15, n_neighbors=5, random_state=42):\n",
    "    \n",
    "    mi_scores = np.zeros((n_runs, X.shape[1]))\n",
    "    \n",
    "    for i in range(n_runs):\n",
    "        mi_scores[i] = mutual_info_classif(\n",
    "            X, y,\n",
    "            n_neighbors=n_neighbors,\n",
    "            random_state=random_state + i\n",
    "        )\n",
    "    \n",
    "    mean_scores = mi_scores.mean(axis=0)\n",
    "    valid_idx = mean_scores > 0.001\n",
    "    return (\n",
    "        pd.Series(mean_scores[valid_idx], index=X.columns[valid_idx]),\n",
    "        mi_scores.std(axis=0)[valid_idx],\n",
    "        valid_idx\n",
    "    )\n",
    "\n",
    "stable_mi, mi_std, valid_idx = compute_stable_mi(X_train, y_train)\n",
    "\n",
    "ig_results = pd.DataFrame({\n",
    "    'Feature': X_train.columns[valid_idx],\n",
    "    'IG_Score': stable_mi.values,\n",
    "    'IG_Variance': mi_std\n",
    "}).sort_values('IG_Score', ascending=False)\n",
    "\n",
    "ig_results['IG_Percentile'] = (ig_results['IG_Score'].rank(pct=True).round(3) * 100)\n",
    "\n",
    "print(\"\\nTop 20 Features by Stable Mutual Information:\")\n",
    "print(ig_results.head(20).to_string(float_format=\"%.4f\"))\n",
    "\n",
    "\n",
    "#-----------------------------------------------------COMBINE RESULTS-----------------------------------------------------------\n",
    "\n",
    "combined_results = (\n",
    "    feature_importance\n",
    "    .merge(chi2_results[['Feature', 'Chi2_Score', 'p_value']], on='Feature', how='left')\n",
    "    .merge(ig_results, on='Feature', how='left')\n",
    ")\n",
    "\n",
    "# Fill NA for features not present in all methods\n",
    "combined_results.fillna({'IG_Score': 0, 'IG_Percentile': 0, 'IG_Variance': 0}, inplace=True)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_n = min(15, len(combined_results))\n",
    "top_features = combined_results.nlargest(top_n, 'Fisher_Score').copy()\n",
    "\n",
    "# Create normalized scores\n",
    "top_features['Fisher_norm'] = top_features['Fisher_Score'] / top_features['Fisher_Score'].max()\n",
    "top_features['Chi2_norm'] = top_features['Chi2_Score'] / top_features['Chi2_Score'].max()\n",
    "top_features['IG_norm'] = top_features['IG_Score'] / top_features['IG_Score'].max()\n",
    "\n",
    "# Plot with proper column names\n",
    "plot_data = top_features.set_index('Feature')[['Fisher_norm', 'Chi2_norm', 'IG_norm']]\n",
    "plot_data.plot(\n",
    "    kind='barh',\n",
    "    color=['#647D65', '#A5C3CF', '#D9D9D9'],\n",
    "    width=0.8,\n",
    "    figsize=(12,8)\n",
    ")\n",
    "\n",
    "plt.title('Feature Importance Comparison Across Methods')\n",
    "plt.xlabel('Normalized Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.legend(['Fisher Score', 'Chi-Squared', 'Mutual Info'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#--------------------------------------------------Combined top features of the three methods---------------------------------------------------\n",
    "\n",
    "print(\"\\nConsensus Features (Important in All Methods):\")\n",
    "consensus = combined_results[\n",
    "    (combined_results['Percentile'] > 60) & \n",
    "    (combined_results['p_value'] < 0.4) &\n",
    "    (combined_results['IG_Percentile'] > 60)\n",
    "]\n",
    "print(consensus[['Feature', 'Fisher_Score', 'Chi2_Score', 'IG_Score']].to_string(float_format=\"%.4f\"))\n",
    "\n",
    "selected_features = consensus['Feature'].tolist()\n",
    "\n",
    "test_features(selected_features)               \n",
    "\n",
    "print('Selected features:')\n",
    "print(selected_features)\n",
    "\n",
    "X_train_selected = X_train_scaled[selected_features].copy()\n",
    "X_test_selected  = X_test_scaled[selected_features].copy()\n",
    "selected_features = list(selected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343fff7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------PCA------------------------------------------------------------------\n",
    "\n",
    "\n",
    "pca = PCA()  \n",
    "pca.fit(X_train_scaled)\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "pca_variance_df = pd.DataFrame({\n",
    "    'Component': [f'PC{i+1}' for i in range(len(explained_variance))],\n",
    "    'Individual_Variance': explained_variance,\n",
    "    'Cumulative_Variance': cumulative_variance\n",
    "})\n",
    "\n",
    "n_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "\n",
    "detailed_variance = pd.DataFrame({\n",
    "    'Component': [f'PC{i+1}' for i in range(len(explained_variance))],\n",
    "    'Eigenvalue': pca.explained_variance_,\n",
    "    'Variance_Ratio': pca.explained_variance_ratio_,\n",
    "    'Cumulative_Variance': cumulative_variance,\n",
    "    'Variance_Percent': pca.explained_variance_ratio_ * 100,\n",
    "    'Cumulative_Percent': cumulative_variance * 100\n",
    "})\n",
    "\n",
    "print(\"\\nDetailed PCA Component Analysis:\")\n",
    "print(detailed_variance.head(15).to_string(float_format=lambda x: f\"{x:.4f}\"))\n",
    "    \n",
    "pca_optimal = PCA(n_components=n_components)\n",
    "X_train_pca = pca_optimal.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca_optimal.transform(X_test_scaled)\n",
    "\n",
    "X_train_pca = pd.DataFrame(\n",
    "    X_train_pca,\n",
    "    columns=[f\"PC{i+1}\" for i in range(n_components)],\n",
    "    index=X_train.index\n",
    ")\n",
    "\n",
    "X_test_pca = pd.DataFrame(\n",
    "    X_test_pca,\n",
    "    columns=[f\"PC{i+1}\" for i in range(n_components)],\n",
    "    index=X_test.index\n",
    ")\n",
    "\n",
    "print(f\"\\nCreated PCA transformed datasets with {n_components} components\")\n",
    "print(f\"X_train_pca shape: {X_train_pca.shape}\")\n",
    "print(f\"X_test_pca shape: {X_test_pca.shape}\")\n",
    "\n",
    "loadings = pd.DataFrame(\n",
    "    pca_optimal.components_.T,\n",
    "    columns=[f'PC{i+1}' for i in range(n_components)],\n",
    "    index=X_train.columns\n",
    ")\n",
    "\n",
    "print(\"\\nPCA Component Loadings (showing 5 features per component):\")\n",
    "for pc in loadings.columns:\n",
    "    print(f\"\\nTop features for {pc}:\")\n",
    "    print(loadings[pc].abs().sort_values(ascending=False).head(5))\n",
    "\n",
    "#-----------------------------------------------------------PLS------------------------------------------------------------------\n",
    "\n",
    "y_train_encoded = LabelEncoder().fit_transform(y_train)\n",
    "n_components = 10\n",
    "\n",
    "pls = PLSRegression(n_components=n_components)\n",
    "X_train_pls = pls.fit_transform(X_train_scaled, y_train_encoded)[0]\n",
    "X_test_pls = pls.transform(X_test_scaled)\n",
    "\n",
    "X_train_pls = pd.DataFrame(X_train_pls, columns=[f'PLS{i+1}' for i in range(n_components)], index=X_train.index)\n",
    "X_test_pls = pd.DataFrame(X_test_pls, columns=[f'PLS{i+1}' for i in range(n_components)], index=X_test.index)\n",
    "\n",
    "pls_loadings = pd.DataFrame(\n",
    "    pls.x_weights_,\n",
    "    columns=[f'PLS{i+1}' for i in range(n_components)],\n",
    "    index=X_train.columns\n",
    ")\n",
    "\n",
    "print(\"PLS Component Loadings (X-weights):\")\n",
    "print(pls_loadings)\n",
    "\n",
    "for component in pls_loadings.columns:\n",
    "    print(f\"\\nTop features for {component}:\")\n",
    "    print(pls_loadings[component].abs().sort_values(ascending=False).head(5))\n",
    "\n",
    "pls_explained_variance = pls.x_scores_.var(axis=0) / pls.x_scores_.var(axis=0).sum()\n",
    "print(\"\\nExplained Variance per PLS Component (X-space):\")\n",
    "print(pd.Series(pls_explained_variance, index=[f'PLS{i+1}' for i in range(n_components)]))\n",
    "\n",
    "print(\"\\nPLS Model Coefficients (for original features):\")\n",
    "print(pd.Series(pls.coef_.flatten(), index=X_train.columns))\n",
    "\n",
    "pls_variance_df = pd.DataFrame({\n",
    "    'Component': [f'PLS{i+1}' for i in range(len(pls_explained_variance))],\n",
    "    'Variance_Ratio': pls_explained_variance,\n",
    "    'Cumulative_PLS': np.cumsum(pls_explained_variance)\n",
    "})\n",
    "\n",
    "#-----------------------------------------------------------PLS and PCA COMPARISON------------------------------------------------------------------\n",
    "\n",
    "\n",
    "print(\"\\n=== PCA vs PLS Explained Variance Comparison ===\")\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Component_Num': range(1, min(len(explained_variance), len(pls_explained_variance))+1),\n",
    "    'PCA_Component': [f'PC{i}' for i in range(1, min(len(explained_variance), len(pls_explained_variance))+1)],\n",
    "    'PCA_Variance': explained_variance[:len(pls_explained_variance)],\n",
    "    'PCA_Cumulative': cumulative_variance[:len(pls_explained_variance)],\n",
    "    'PLS_Component': [f'PLS{i}' for i in range(1, min(len(explained_variance), len(pls_explained_variance))+1)],\n",
    "    'PLS_Variance': pls_explained_variance,\n",
    "    'PLS_Cumulative': np.cumsum(pls_explained_variance)\n",
    "})\n",
    "\n",
    "print(comparison_df.head(10).to_string(float_format=lambda x: f\"{x:.4f}\"))\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar([i-0.2 for i in range(1, 11)], explained_variance[:10], width=0.4, label='PCA', alpha=0.7)\n",
    "plt.bar([i+0.2 for i in range(1, 11)], pls_explained_variance[:10], width=0.4, label='PLS', alpha=0.7)\n",
    "plt.xlabel('Component Number')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.title('PCA vs PLS: Individual Explained Variance')\n",
    "plt.legend()\n",
    "plt.xticks(range(1, 11))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, 11), cumulative_variance[:10], 'o-', label='PCA', markersize=4)\n",
    "plt.plot(range(1, 11), np.cumsum(pls_explained_variance)[:10], 's-', label='PLS', markersize=4)\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% Threshold')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('PCA vs PLS: Cumulative Explained Variance')\n",
    "plt.legend()\n",
    "plt.xticks(range(1, 11))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03093276",
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------MODELS FUNCTIONS------------------------------------------------\n",
    "\n",
    "def run_logistic_regression(X_train, y_train, X_test, y_test, \n",
    "                          max_iter=100000, solver='saga', C=0.01, \n",
    "                          class_weight='balanced', dataset_name=''):\n",
    "    \"\"\"Logistic regression model.\"\"\"\n",
    "    model = LogisticRegression(max_iter=max_iter, solver=solver, \n",
    "                             C=C, class_weight=class_weight)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    \n",
    "    print('Logistic Regression Results:')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(classification_report(y_test, preds))\n",
    "    print(confusion_matrix(y_test, preds))\n",
    "    \n",
    "    plot_confusion_matrix(y_test, preds, 'Logistic Regression', dataset_name)\n",
    "    \n",
    "    # Feature importance plot\n",
    "    if hasattr(model, 'coef_') and hasattr(X_train, 'columns'):\n",
    "        importances = np.abs(model.coef_[0])\n",
    "        plot_feature_importance(importances, X_train, \"Logistic Regression\")\n",
    "    \n",
    "    return model, preds, accuracy\n",
    "\n",
    "def run_svm(X_train, y_train, X_test, y_test, kernel='rbf', \n",
    "           class_weight='balanced', probability=True, dataset_name=''):\n",
    "    \"\"\"SVM model.\"\"\"\n",
    "    model = SVC(kernel=kernel, class_weight=class_weight, probability=probability)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    \n",
    "    print('SVM Results:')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(classification_report(y_test, preds))\n",
    "    print(confusion_matrix(y_test, preds))\n",
    "    \n",
    "    plot_confusion_matrix(y_test, preds, 'SVM', dataset_name)\n",
    "    \n",
    "    if hasattr(X_train, 'columns'):\n",
    "        result = permutation_importance(model, X_test, y_test, \n",
    "                                      n_repeats=10, random_state=42)\n",
    "        plot_feature_importance(result.importances_mean, X_train, \"SVM\")\n",
    "    \n",
    "    return model, preds, accuracy\n",
    "\n",
    "def run_random_forest(X_train, y_train, X_test, y_test, n_estimators=100, \n",
    "                     max_depth=12, max_features='sqrt', min_samples_leaf=3, \n",
    "                     min_samples_split=2, random_state=42, dataset_name=''):\n",
    "    \"\"\"Random Forest model.\"\"\"\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators, max_depth=max_depth, max_features=max_features,\n",
    "        min_samples_leaf=min_samples_leaf, min_samples_split=min_samples_split,\n",
    "        random_state=random_state\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    \n",
    "    print('Random Forest Results:')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(classification_report(y_test, preds))\n",
    "    print(confusion_matrix(y_test, preds))\n",
    "    \n",
    "    plot_confusion_matrix(y_test, preds, \"Random Forest\", dataset_name)\n",
    "    plot_feature_importance(model.feature_importances_, X_train, \"Random Forest\")\n",
    "    \n",
    "    return model, preds, accuracy\n",
    "\n",
    "def run_xgboost(X_train, y_train, X_test, y_test, learning_rate=0.1, \n",
    "               max_depth=3, min_child_weight=1, subsample=0.8, \n",
    "               colsample_bytree=0.8, n_estimators=100, gamma=0, \n",
    "               random_state=42, dataset_name=''):\n",
    "    \"\"\"XGBoost model.\"\"\"\n",
    "    model = XGBClassifier(\n",
    "        learning_rate=learning_rate, max_depth=max_depth, \n",
    "        min_child_weight=min_child_weight, subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree, n_estimators=n_estimators,\n",
    "        gamma=gamma, random_state=random_state, eval_metric='logloss',\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    \n",
    "    print('XGBoost Results:')\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(classification_report(y_test, preds))\n",
    "    print(confusion_matrix(y_test, preds))\n",
    "    \n",
    "    plot_confusion_matrix(y_test, preds, \"XGBoost\", dataset_name)\n",
    "    plot_feature_importance(model.feature_importances_, X_train, \"XGBoost\")\n",
    "    \n",
    "    return model, preds, accuracy\n",
    "\n",
    "def run_lightgbm(X_train, y_train, X_test, y_test, n_estimators=100, \n",
    "                learning_rate=0.1, max_depth=5, num_leaves=31, \n",
    "                class_weight='balanced', random_state=42, dataset_name=''):\n",
    "    \"\"\"LightGBM model.\"\"\"\n",
    "    model = LGBMClassifier(\n",
    "        n_estimators=n_estimators, learning_rate=learning_rate,\n",
    "        max_depth=max_depth, num_leaves=num_leaves,\n",
    "        class_weight=class_weight, random_state=random_state\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    \n",
    "    print(\"LightGBM Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(classification_report(y_test, preds))\n",
    "    print(confusion_matrix(y_test, preds))\n",
    "    \n",
    "    plot_confusion_matrix(y_test, preds, \"LightGBM\", dataset_name)\n",
    "    plot_feature_importance(model.feature_importances_, X_train, \"LightGBM\")\n",
    "    \n",
    "    return model, preds, accuracy\n",
    "\n",
    "#------------------------------------------------------------PLOTS-------------------------------------------------------------\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, model_name, dataset_name):\n",
    "    \"\"\"Universal confusion matrix plot for all models.\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Choose color scheme based on model type\n",
    "    if 'Random Forest' in model_name:\n",
    "        cmap = 'Oranges'\n",
    "        bg_color = '#f5f5f5'\n",
    "    elif 'XGBoost' in model_name:\n",
    "        cmap = 'Oranges'\n",
    "        bg_color = '#f0f8ff'\n",
    "    elif 'LightGBM' in model_name:\n",
    "        cmap = 'Oranges'\n",
    "        bg_color = '#fffaf0'\n",
    "    else:  # Logistic Regression, SVM\n",
    "        cmap = 'Reds'\n",
    "        bg_color = None\n",
    "    \n",
    "    ax = sns.heatmap(\n",
    "        cm, \n",
    "        annot=True, \n",
    "        fmt='d', \n",
    "        cmap=cmap,\n",
    "        annot_kws={'size': 16, 'weight': 'bold'},\n",
    "        cbar=False,            \n",
    "        linewidths=1,          \n",
    "        linecolor='lightgray'   \n",
    "    )\n",
    "    \n",
    "    plt.title(\n",
    "        f'{model_name} Confusion Matrix\\n{dataset_name}', \n",
    "        pad=20, fontsize=16, weight='bold'\n",
    "    )\n",
    "    plt.xlabel('Predicted Label', fontsize=14, weight='bold', labelpad=10)\n",
    "    plt.ylabel('True Label', fontsize=14, weight='bold', labelpad=10)\n",
    "    \n",
    "    ax.set_xticklabels(ax.get_xticklabels(), fontsize=14, weight='bold')\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=14, weight='bold')\n",
    "    \n",
    "    if bg_color:\n",
    "        plt.gca().set_facecolor(bg_color)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_importance(importances, X_train, model_name, top_n=8):\n",
    "    \"\"\"Universal feature importance plot for all models.\"\"\"\n",
    "    # Handle both DataFrame and numpy array cases\n",
    "    if hasattr(X_train, 'columns'):\n",
    "        feature_names = X_train.columns\n",
    "    else:\n",
    "        feature_names = [f'Feature {i}' for i in range(X_train.shape[1])]\n",
    "    \n",
    "    # Sort features by importance\n",
    "    sorted_indices = np.argsort(importances)[::-1]\n",
    "    n_features = min(top_n, len(feature_names))\n",
    "    top_indices = sorted_indices[:n_features]\n",
    "    \n",
    "    # Choose colors based on model type\n",
    "    if 'Random Forest' in model_name or 'XGBoost' in model_name or 'LightGBM' in model_name:\n",
    "        color = '#A5C3CF'\n",
    "    else:  # Logistic Regression, SVM\n",
    "        color = '#AC3E3E'\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(f\"Top Feature Importances - {model_name}\")\n",
    "    plt.barh(range(n_features), importances[top_indices], \n",
    "             align='center', color=color, height=0.7)\n",
    "    plt.yticks(range(n_features), np.array(feature_names)[top_indices])\n",
    "    \n",
    "    # Customize x-label based on model type\n",
    "    if 'SVM' in model_name:\n",
    "        plt.xlabel(\"Mean Accuracy Decrease After Permutation\")\n",
    "    elif any(tree_model in model_name for tree_model in ['Random Forest', 'XGBoost', 'LightGBM']):\n",
    "        plt.xlabel(\"Importance Score\")\n",
    "    else:  # Logistic Regression\n",
    "        plt.xlabel(\"Absolute Coefficient Value\")\n",
    "    \n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "#----------------------------------------------------------------RUN FUNCTIONS--------------------------------------------------\n",
    "\n",
    "datasets = [\n",
    "    ('Original', X_train, y_train, X_test, y_test),\n",
    "    ('Scaled', X_train_scaled, y_train, X_test_scaled, y_test),\n",
    "    ('Combined', X_train_combined, y_train, X_test_combined, y_test),\n",
    "    ('Selected', X_train_selected, y_train, X_test_selected, y_test),\n",
    "    ('Forward selection', X_train_FS, y_train, X_test_FS, y_test),\n",
    "    ('Domain', X_train_domain, y_train, X_test_domain, y_test),\n",
    "    ('PCA', X_train_pca, y_train, X_test_pca, y_test),\n",
    "    ('PLS', X_train_pls, y_train, X_test_pls, y_test)\n",
    "]\n",
    "\n",
    "model_functions = {\n",
    "    'Logistic Regression': run_logistic_regression,\n",
    "    'SVM': run_svm,\n",
    "    'Random Forest': run_random_forest,\n",
    "    'XGBoost': run_xgboost,\n",
    "    'LightGBM': run_lightgbm\n",
    "}\n",
    "\n",
    "\n",
    "all_accuracies = {model_name: {} for model_name in model_functions.keys()}\n",
    "\n",
    "#Run all models on all datasets\n",
    "for model_name, model_func in model_functions.items():\n",
    "    \n",
    "    print(f\"RUNNING {model_name.upper()} MODELS\")\n",
    "    \n",
    "    for dataset_name, X_tr, y_tr, X_te, y_te in datasets:\n",
    "        print(f\"\\n--- {model_name} on {dataset_name} Dataset ---\")\n",
    "        try:\n",
    "            _, _, acc = model_func(X_tr, y_tr, X_te, y_te, dataset_name=dataset_name)\n",
    "            all_accuracies[model_name][dataset_name] = acc\n",
    "        except Exception as e:\n",
    "            print(f\"Error running {model_name} on {dataset_name}: {str(e)}\")\n",
    "            all_accuracies[model_name][dataset_name] = 0.0\n",
    "\n",
    "print(\"FINAL ACCURACY SUMMARY\")\n",
    "\n",
    "for model_name in all_accuracies:\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for dataset_name, acc in all_accuracies[model_name].items():\n",
    "        print(f\"  {dataset_name:15}: {acc:.4f}\")\n",
    "\n",
    "#Best perfoming model\n",
    "best_acc = 0\n",
    "best_combo = \"\"\n",
    "for model_name in all_accuracies:\n",
    "    for dataset_name, acc in all_accuracies[model_name].items():\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_combo = f\"{model_name} on {dataset_name}\"\n",
    "\n",
    "print(f\"\\nBest Performance: {best_combo} with accuracy {best_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
